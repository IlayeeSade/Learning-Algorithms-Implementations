{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90TZOzpC87TU"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eFVO6B56OWZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDuOwNox4ilm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1866a6e9-137d-4fbb-d1e4-d6a3be2cdc99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = torch.from_numpy(x_train).float().to(device)\n",
        "y_train = torch.from_numpy(y_train).float().to(device)\n",
        "x_test = torch.from_numpy(x_test).float().to(device)\n",
        "y_test = torch.from_numpy(y_test).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg6UzaSkLxnu",
        "outputId": "ddc6aae9-ca1c-4f7f-dcac-3afcc7f47bdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "torch.isnan(x_train).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h16N11U4Krw6"
      },
      "outputs": [],
      "source": [
        "mean = torch.mean(x_train, dim=0)\n",
        "std = torch.std(x_train, dim=0) + 1e-8\n",
        "x_train = x_train - mean\n",
        "x_train = x_train / std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cmOI7thLtxc",
        "outputId": "bcaddfdb-d749-4f81-8c71-773e85783a1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.isnan(mean).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GsGU0a6MNRg",
        "outputId": "75f37796-91dc-4b4b-8f7a-2cbb6d85b611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "torch.isnan(std).any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRhEiYAjLqIP",
        "outputId": "0fa325c3-e5e9-445d-d0da-c4846e7093fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(False, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "torch.isnan(x_train).any()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UpsampleBlock(nn.Module):\n",
        "  def __init__(self, in_channels, ini=True):\n",
        "    super(UpsampleBlock, self).__init__()\n",
        "    reg = torch.sqrt(torch.tensor(2/(in_channels*4*4)))\n",
        "    self.seq = nn.Sequential(\n",
        "        nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=4, padding=1, stride=2) * reg if ini else nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=4, padding=1, stride=2),\n",
        "        nn.BatchNorm2d(in_channels // 2),\n",
        "        nn.LeakyReLU(0.1),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.seq(x)"
      ],
      "metadata": {
        "id": "PjFQog1k42F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Noiser(nn.Module):\n",
        "  def __init__(self, amplitude_seq):\n",
        "    super(Noiser, self).__init__()\n",
        "    self.seq = amplitude_seq\n",
        "\n",
        "  def forward(self, x, iter):\n",
        "    return x + torch.randn_like(x) * self.seq[iter]"
      ],
      "metadata": {
        "id": "bVVvbGuv6oEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, amplitude_seq):\n",
        "    super(Generator, self).__init__()\n",
        "    self.entry = nn.Sequential(\n",
        "        # Entry\n",
        "        nn.Linear(16, 16 * 64) * torch.sqrt(torch.tensor(2/16)),\n",
        "        nn.Unflatten(1, (64, 4, 4)),\n",
        "        nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1, stride=2) * torch.sqrt(torch.tensor(2/(32*4*4))),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(0.1)\n",
        "    )\n",
        "    self.block1 = UpsampleBlock(32)\n",
        "    self.block2 = UpsampleBlock(16)\n",
        "    self.finisher = nn.Conv2d(8, 1, kernel_size=1, stride=1)\n",
        "    self.Noiser = Noiser(amplitude_seq)\n",
        "\n",
        "  def forward(self, x, iter):\n",
        "    x = self.entry(x)\n",
        "    x = self.block1(x)\n",
        "    if not self.training:\n",
        "      x = self.Noiser(x, iter)\n",
        "    x = self.block2(x)\n",
        "    if not self.training:\n",
        "      x = self.Noiser(x, iter)\n",
        "    return self.finisher(x)"
      ],
      "metadata": {
        "id": "sCWocKBn4ty4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htpefn9ju2Vu"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 256\n",
        "N_SAMPLES = x_train.shape[0]\n",
        "ITERS = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "noise_ampli = torch.exp(torch.exp(torch.exp(torch.linspace(1, 0, steps=300)))) - torch.exp(torch.exp(torch.tensor(1)))\n",
        "noise_ampli = noise_ampli / noise_ampli[0] * 0.3\n",
        "noise_ampli = noise_ampli.to(device)"
      ],
      "metadata": {
        "id": "2fktWRphYzGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Discriminator = nn.Sequential(\n",
        "    nn.Conv2d(1, 32, kernel_size=4, padding=1, stride=2) torch.sqrt(torch.tensor(2/(1*4*4))),\n",
        "    nn.Conv2d(32, 64, kernel_size=4, padding=1, stride=2) * torch.sqrt(torch.tensor(2/(32*4*4))),\n",
        "    nn.BatchNorm2d(64),\n",
        "    nn.LeakyReLU(0.1),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(7 * 7 * 64, 16) * torch.sqrt(torch.tensor(2/(7*7*64))),\n",
        "    nn.BatchNorm1d(16),\n",
        "    nn.LeakyReLU(0.1),\n",
        "    nn.Linear(16, 1) * torch.sqrt(torch.tensor(2/(16))),\n",
        ").to(device)\n",
        "\n",
        "Generator = Generator(noise_ampli).to(device)"
      ],
      "metadata": {
        "id": "6hHN5M3y6-sN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "fdb28dc0-2813-447a-85ea-b4dd3ebc7e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-14-2a9329eef6d5>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-2a9329eef6d5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    nn.Conv2d(1, 32, kernel_size=4, padding=1, stride=2) torch.sqrt(torch.tensor(2/(1*4*4))),\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optim_dis = torch.optim.Adam(Discriminator.parameters(), lr = 3e-4)\n",
        "optim_gen = torch.optim.Adam(Generator.parameters(), lr = 3e-4)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()"
      ],
      "metadata": {
        "id": "250spqrJ7E0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def noisify_labels(labels):\n",
        "    mu = 0\n",
        "    sigma = 0.020\n",
        "    noise = torch.normal(mean=mu, std=sigma, size=labels.shape) # Match the shape of labels\n",
        "    noise = torch.abs(noise)\n",
        "    noisy_labels = labels.clone().float()  # Cast to float to support noise addition\n",
        "\n",
        "    # Use .view(-1) to ensure both are 1D\n",
        "    noisy_labels = noisy_labels.view(-1).to(device)\n",
        "    labelsv = labels.view(-1).to(device)\n",
        "    noise = noise.view(-1).to(device)\n",
        "\n",
        "    noisy_labels[labelsv == 0] += noise[labelsv == 0] # Flatten labels for indexing\n",
        "    noisy_labels[labelsv == 1] -= noise[labelsv == 1] # Flatten labels for indexing\n",
        "\n",
        "    return noisy_labels.reshape(labels.shape) # Reshape to original shape"
      ],
      "metadata": {
        "id": "X-Mq0XSPXBT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiFyJ3Xhwnln"
      },
      "outputs": [],
      "source": [
        "def train_gen(iter):\n",
        "  for _ in range(ITERS):\n",
        "    # Gen Data\n",
        "    batch_x = Generator(torch.randn(BATCH_SIZE, 16).to(device), iter).to(device)\n",
        "    preds = Discriminator(batch_x).to(device)\n",
        "\n",
        "    loss = criterion(preds, noisify_labels(torch.ones_like(preds).to(device))) # L = log(D(G(Z)))\n",
        "\n",
        "    # Backpropagation for generator\n",
        "    optim_gen.zero_grad()\n",
        "    loss.backward()\n",
        "    optim_gen.step()\n",
        "\n",
        "def train_dis(iter):\n",
        "  for _ in range(ITERS):\n",
        "    # Real data\n",
        "    ix = torch.randint(0, N_SAMPLES, (BATCH_SIZE,)).to(device)\n",
        "    batch_x = x_train[ix].unsqueeze(1).to(device)\n",
        "    preds_r = Discriminator(batch_x).to(device)\n",
        "    r_loss = criterion(preds_r, noisify_labels(torch.ones_like(preds_r).to(device)))\n",
        "\n",
        "    # Gen data\n",
        "    batch_x = Generator(torch.randn(BATCH_SIZE, 16).to(device), iter).to(device)\n",
        "    preds_g = Discriminator(batch_x)\n",
        "    g_loss = criterion(preds_g, noisify_labels(torch.zeros_like(preds_g)))\n",
        "\n",
        "    # Total loss\n",
        "    loss = r_loss + g_loss # L = ( log(D(X)) + log(1-D(G(Z))) ) / 2\n",
        "\n",
        "    # Backpropagation for discriminator\n",
        "    optim_dis.zero_grad()\n",
        "    loss.backward()\n",
        "    optim_dis.step("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18koJiwx0TmK"
      },
      "outputs": [],
      "source": [
        "def sample_gen(num_images):\n",
        "    Generator.eval()\n",
        "    plt.figure(figsize=(num_images * 3, 3))\n",
        "    for i in range(num_images):\n",
        "        tensor = Generator(torch.randn(2, 16)[0, :].unsqueeze(0).to(device), 1)\n",
        "        tensor = (tensor * std.to(device)) + mean.to(device)\n",
        "        image = tensor.detach().cpu().numpy().reshape(28, 28)\n",
        "\n",
        "        # Plot the image\n",
        "        plt.subplot(1, num_images, i + 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')  # Optional: remove axes for a cleaner look\n",
        "    plt.show()\n",
        "    Generator.train()\n",
        "\n",
        "def sample_reg():\n",
        "  tensor = x_train[0]\n",
        "  image = tensor.detach().cpu().numpy().reshape(28,28)\n",
        "\n",
        "  # Plot the image\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.axis('off')  # Optional: remove axes for a cleaner look\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAgRuJCE3PKX"
      },
      "outputs": [],
      "source": [
        "gen_loss = []\n",
        "dis_loss = []\n",
        "for i in range(300):\n",
        "  print(f'iteration: {i}')\n",
        "  sample_gen(6)\n",
        "\n",
        "  batch = Generator(torch.randn(BATCH_SIZE, 16).to(device), i)\n",
        "  loss = criterion(Discriminator(batch).to(device), torch.zeros(BATCH_SIZE, 1).to(device)).item()\n",
        "  while(True):\n",
        "    prev_loss = loss\n",
        "    batch = Generator(torch.randn(BATCH_SIZE, 16).to(device), i)\n",
        "    loss = criterion(Discriminator(batch).to(device), torch.ones(BATCH_SIZE, 1).to(device)).item()\n",
        "    if(np.abs(prev_loss-loss)<1e-2):\n",
        "      gen_loss.append(loss)\n",
        "      break\n",
        "    train_gen(i)\n",
        "\n",
        "  batch = Generator(torch.randn(BATCH_SIZE, 16).to(device), i)\n",
        "  loss = criterion(Discriminator(batch).to(device), torch.zeros(BATCH_SIZE, 1).to(device)).item()\n",
        "  while(True):\n",
        "    prev_loss = loss\n",
        "    batch = Generator(torch.randn(BATCH_SIZE, 16).to(device), i)\n",
        "    loss = criterion(Discriminator(batch).to(device), torch.zeros(BATCH_SIZE, 1).to(device)).item()\n",
        "    if(np.abs(prev_loss-loss)<1e-3):\n",
        "      dis_loss.append(loss)\n",
        "      break\n",
        "    train_dis(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRTjm_--3AUP"
      },
      "outputs": [],
      "source": [
        "plt.plot(gen_loss)\n",
        "plt.plot(dis_loss)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTBgyAS4o0ia"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}